{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complete-maine",
   "metadata": {
    "id": "unlikely-thomson"
   },
   "source": [
    "### Développement d’un pipeline de calcul du TMB\n",
    "\n",
    "#### Projet 4BiM, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-shepherd",
   "metadata": {
    "id": "premier-shepherd"
   },
   "source": [
    "#### Auteurs : Marie Casimir, Loup Petitjean et Nicolas Mendiboure\n",
    "#### Encadrantes Innate-Pharma : Sabrina Carpentier et Luciana Bastista\n",
    "#### Encadrante INSA : Maïwenn Pineau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R_N6O2NoP9iW",
   "metadata": {
    "id": "R_N6O2NoP9iW"
   },
   "source": [
    "### Installation et import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proper-night",
   "metadata": {
    "id": "proper-night"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os \n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-snake",
   "metadata": {},
   "source": [
    "## Importation de vcf sample1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "german-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_extension(path):\n",
    "    \"\"\"\n",
    "    Argument :\n",
    "        \n",
    "        path : string, chemin vers le fichier à vérifier.\n",
    "        \n",
    "        Cette fonction permet de bien vérifier que le fichier d'entré contient\n",
    "    bien l'extension .vcf.\n",
    "    \n",
    "    Attention : sur Windows cela peut poser un problème car les extensions de fichiers \n",
    "    ne sont pas toujours apparentes dans les chemins.\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "        True ou False si le fichier est dans les normes.\n",
    "    \"\"\"\n",
    "    \n",
    "    split = path.split(\".\")\n",
    "    format_name = len(split) -1 \n",
    "\n",
    "    if (split[format_name].lower() != \"vcf\"):\n",
    "        print(\"Votre fichier n'est pas au bon format, format attendu : vcf\")\n",
    "        return(False)\n",
    "    else :\n",
    "        print(\"Succès : extension vcf détectée\")\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_format(path):\n",
    "    \"\"\"\n",
    "    Argument :\n",
    "    \n",
    "        path : string, chemin vers le fichier à vérifier.\n",
    "        \n",
    "        Dans tous le fichiers VCF, la première informative doit être de la forme : ##format=VCFv4.x.\n",
    "    Cette fonction permet de le vérifier, elle renvoie True dans le cas échéant et False sinon.\n",
    "    \n",
    "    Return :\n",
    "        \n",
    "        True ou False si le fichier est dans les normes.\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        line = f.readline()\n",
    "    \n",
    "    if (line.find(\"VCF\") != -1): #Si on trouve 'VCF' dans line \n",
    "        return (True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satellite-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_data(df):\n",
    "    \"\"\"\n",
    "    Argument : \n",
    "    \n",
    "        df : dataframe.\n",
    "    \n",
    "        Cette fonction permet de vérifier si le fichier vcf n'est pas érroné.\n",
    "    Pour cela on regarde qu'il ne manque pas de colonne, s'il en manque, la fonction \n",
    "    renvoie False avec le nom de la colonne manquante.\n",
    "    On vérifie ensuite qu'il ne manque pas d'information sur chaque variant  (ou ligne),\n",
    "    pour cela on regarde qu'il n'y ait pas de NaN. S'il y a trop de NaN, elle return False,\n",
    "    si le nombre de NaN est faible comparé à la taille du fichier, on supprime les lignes où\n",
    "    sont localisés les NaN.\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "        -1 :  le fichier n'est pas bon on le rejette ;\n",
    "        \n",
    "        0 : Le fichier est à la limite de l'acceptable (quelques NaN) \n",
    "        et peut subir une modification pour traiter les NaN ;\n",
    "        \n",
    "        1 : Le fichier est validé.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Vérifier  qu'il ne manque pas une colonne dans le ficher :\n",
    "    columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT']\n",
    "    for col in columns:\n",
    "        if (col not in df.columns):\n",
    "            print(\"Ce fichier vcf est incomplet\")\n",
    "            print(\"Il manque la colonne {}\".format(col))\n",
    "            return (-1)\n",
    "        \n",
    "    #Vérifier que chaque ligne est bien complète (pas de NaN): \n",
    "    NaN_col = df.isna().sum(axis=0)\n",
    "    NaN_cutoff = 3 #nombre de NaN admissibles par fichier vcf, au dèla fichier rejetté.\n",
    "    \n",
    "    if (sum(NaN_col) !=0) : #s'il y a des NaN\n",
    "        if (sum(NaN_col) <= NaN_cutoff) :\n",
    "            return(0)\n",
    "            \n",
    "        else:\n",
    "            print(\"Votre fichier un nombre de données manquantes trop élevé.\")\n",
    "            print(\"Veuillez fournir un vcf de meilleur qualité.\")\n",
    "            return (-1)\n",
    "    else:\n",
    "        print(\"Contrôle des NaN : Ok\")\n",
    "        return(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unavailable-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_NaN_rows(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Argument: \n",
    "    \n",
    "        df : dataframe.\n",
    "        \n",
    "        Cette fonctionne permet de supprimer les lignes dans lesquelles on aurait des NaN.\n",
    "    \n",
    "    Return :\n",
    "    \n",
    "        new_df : dataframe dont les lignes contenant des 'NaN' ont été supprimées.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_df = copy.deepcopy(df) # Pour ne pas ecraser notre df initial \n",
    "    NaN_line = df.isna().sum(axis=1)\n",
    "    indexes = []\n",
    "    for i, line in enumerate(NaN_line.values):\n",
    "                if (line != 0):\n",
    "                    indexes.append(i)\n",
    "    for idx in indexes :\n",
    "                new_df = df.drop([idx], axis = 0)\n",
    "            \n",
    "    print(\"Suppression des NaN : Ok\")      \n",
    "    return (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entitled-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_control(df, verbose = True):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "\n",
    "        df : dataframe à controler.\n",
    "\n",
    "        Cette fonction fait appel à notre fonction check_missing_data,\n",
    "    elle fait une synthèse sur la qualité de notre fichier au moment de l'importer\n",
    "    dans la fonction read_vcf.\n",
    "\n",
    "    Return :\n",
    "\n",
    "        df : dataframe avec contrôle qualité effectué.\n",
    "    \"\"\"\n",
    "\n",
    "    miss = check_missing_data(df)\n",
    "    #print(miss)\n",
    "\n",
    "    if (miss == 0):\n",
    "        if(verbose):\n",
    "            print(\"contrôle qualité du VCF : Mauvais. \\n\")\n",
    "        return (False)\n",
    "\n",
    "    elif (miss == 1):\n",
    "        if(verbose):\n",
    "            print(\"Contrôle qualité du VCF : Bon. \\n\")\n",
    "        return (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "freelance-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf(path, verbose = True):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "\n",
    "        path : string,  chemin vers le fichier vcf à importer ;\n",
    "\n",
    "        Cette fonction permet d'importer un fichier vcf et de le convertir en dataframe.\n",
    "    Il y a la possiblité de faire en amont un contrôle qualité via l'appel de la fonction quality_control\n",
    "    si QC == True, sinon importation classique.\n",
    "\n",
    "    Return :\n",
    "\n",
    "        vcf_df : dataframe du fichier vcf importé.\n",
    "    \"\"\"\n",
    "    if (check_extension(path) == True) :\n",
    "        if (verbose):\n",
    "            print(\"Succès : extension vcf détectée pour le fichier{}\".format(path))\n",
    "            print(\"\\n\")\n",
    "\n",
    "        try:\n",
    "            if (check_format(path) == True) :\n",
    "                if (verbose):\n",
    "                    print(\"Succès : Format VCF détecté pour le fichier{}\".format(path))\n",
    "                with open(path, 'r') as f:\n",
    "                    lines = [l for l in f if not l.startswith('##')]\n",
    "\n",
    "                vcf_df = pd.read_csv( io.StringIO(''.join(lines)), dtype={'#CHROM': str, 'POS': int, 'ID': str,\n",
    "                                                                       'REF': str, 'ALT': str,'QUAL': str,\n",
    "                                                                       'FILTER': str, 'INFO': str, 'FORMAT': str},\n",
    "                                 sep='\\t').rename(columns={'#CHROM': 'CHROM'})\n",
    "\n",
    "                return(vcf_df)\n",
    "\n",
    "        except IOError :\n",
    "            if(verbose):\n",
    "                print(\"Fichier introuvable. \\n\")\n",
    "            return(False)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-traffic",
   "metadata": {},
   "source": [
    "## Contrôle des filtres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caroline-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_filter(df, reject = ['LowQual', 'INDEL_SPECIFIC_FILTERS;LowQual']):\n",
    "\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "\n",
    "        df : dataframe issu d'un vcf ;\n",
    "\n",
    "        reject : liste des filtres à ne pas garder.\n",
    "\n",
    "\n",
    "        Cette fonction permet de filtrer (supprimer les lignes) des variants d'un dataframe\n",
    "    dont le 'FILTER' est contenu dans la liste 'reject'.\n",
    "\n",
    "    Return :\n",
    "\n",
    "        new_df : le dataframe filtré.\n",
    "    \"\"\"\n",
    "    new_df = copy.deepcopy(df)\n",
    "\n",
    "    for muta in df.index: #idem que dans quality_filter_normal, on enleve les filters de mauvaise qualite\n",
    "        if df[\"FILTER\"][muta] in reject:\n",
    "            new_df = df.drop(labels = muta, axis=0)\n",
    "\n",
    "    new_df.index = range(0, len(new_df), 1)  #reajustement des indexes apres le drop\n",
    "    print(\"Filtrage des variants de qualité :\", *reject, sep='\\n')\n",
    "\n",
    "    return (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eastern-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_filter_normal(df_normal, reject = ['LowQual', 'INDEL_SPECIFIC_FILTERS;LowQual'], index = True):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "\n",
    "        df_normal : dataframe issu d'un vcf de tissu sain ;\n",
    "\n",
    "        reject : liste des filtres à ne pas garder ;\n",
    "\n",
    "        index : booleen qui indique le revoie ou non d'un indexe.\n",
    "\n",
    "        Cette fonction permet de filtrer (supprimer les lignes) des variants d'un dataframe issus d'un tissu normal\n",
    "    dont le 'FILTER' est contenu dans la liste 'reject'.\n",
    "    Chaque ligne supprimée se retrouve indexée et par son numero de chromosome et par la position du variant\n",
    "    dans un tuple afin de les supprimer également en aval dans le dataframe tumoral.\n",
    "\n",
    "    Return :\n",
    "\n",
    "        df_n : le dataframe normal filtré ;\n",
    "\n",
    "        indexes : liste de tuples contenant les #chrom et les positions des variants supprimés\n",
    "            sur le dataframe normal pour appliquer la même opération sur le dataframe tumoral.\n",
    "    \"\"\"\n",
    "\n",
    "    df_n = copy.deepcopy(df_normal) #deep copy pour ne pas ecraser l'original\n",
    "    indexes = []\n",
    "\n",
    "    for muta in df_normal.index:\n",
    "        if df_normal[\"FILTER\"][muta] in reject:\n",
    "\n",
    "            #On stocke le #CHROM et la #POS correspondant dans un tuple,\n",
    "            #pour effectuer la même suppression dans notre fichier tumoral apres :\n",
    "            indexes.append( (df_normal[\"CHROM\"][muta], df_normal[\"POS\"][muta]))\n",
    "\n",
    "            #On supprime ensuite la ligne correspondante car mauvaise qualite\n",
    "            df_n = df_normal.drop(labels = muta, axis=0)\n",
    "\n",
    "    df_n.index = range(0, len(df_n), 1) #reajustement des indexes apres le drop\n",
    "\n",
    "    if (index == True):\n",
    "        return(df_n, indexes)\n",
    "    else:\n",
    "        return(df_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funded-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_filter_tumor(df_tumor, index_normal, reject = ['LowQual', 'INDEL_SPECIFIC_FILTERS;LowQual']):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "\n",
    "        df_tumor : dataframe issu d'un vcf de tissu tumoral ;\n",
    "\n",
    "        index_normal : liste de tuples contenant les #chrom et les positions des variants supprimés\n",
    "                        pour appliquer la même opération sur le dataframe tumoral;\n",
    "\n",
    "        reject : liste des filtres à ne pas garder ;\n",
    "\n",
    "        Cette fonction permet de filtrer un dataframe issu d'un tissu tumoral.\n",
    "    Dans un premier temps on supprime tous ce qui a été supprimé dans le dataframe normal complémentaire.\n",
    "    Ensuite on supprime les varaiants dont le 'FILTER' est contenu dans la liste 'reject'\n",
    "\n",
    "    Return :\n",
    "\n",
    "        df_t : dataframe tumoral filtré.\n",
    "    \"\"\"\n",
    "\n",
    "    #print(np.unique([index_normal[i][0] for i in range(len(index_normal)) ] ) )\n",
    "\n",
    "    df_t = copy.deepcopy(df_tumor) #deep copy pour ne pas ecraser l'original\n",
    "\n",
    "    for chrom_pos in index_normal: #chrom_pos : tuple (#CHROM, #POS)\n",
    "        chrom = chrom_pos[0] #CHROM\n",
    "        pos = chrom_pos[1] #POS\n",
    "        if(pos in df_tumor[\"POS\"].loc[df_tumor[\"CHROM\"] == chrom].values): #on regarde si la position indexee de df_normal est aussi dans df_tumor\n",
    "            tmp_index = int(np.argwhere(df_tumor[\"POS\"].loc[df_tumor[\"CHROM\"] == chrom].values == pos)) #indexe de cette position\n",
    "            #print(chrom, pos, tmp_index)\n",
    "            df_t = df_tumor.drop(labels = tmp_index, axis=0) #on supprime la ligne ou il y a cette position\n",
    "\n",
    "        if(len(np.unique([index_normal[i][0] for i in range(len(index_normal)) ] )) > 1):\n",
    "            df_t.index = range(0, len(df_t), 1)\n",
    "\n",
    "    for muta in df_t.index: #idem que dans quality_filter_normal, on enleve les filters de mauvaise qualite\n",
    "        if df_tumor[\"FILTER\"][muta] in reject:\n",
    "            df_t = df_tumor.drop(labels = muta, axis=0)\n",
    "\n",
    "    df_t.index = range(0, len(df_t), 1)  #reajustement des indexes apres le drop\n",
    "\n",
    "    return (df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dynamic-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_filter(df_tumor, df_normal, reject = ['LowQual', 'INDEL_SPECIFIC_FILTERS;LowQual']):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "    \n",
    "        df_tumor : dataframe issu d'un vcf de tissu tumoral ;\n",
    "        \n",
    "        df_normal : dataframe issu d'un vcf de tissu sain ;\n",
    "        \n",
    "        reject : liste des filtres à ne pas garder ;\n",
    "        \n",
    "        Fonction qui prend en entrée 2 fichiesr vcf complémentaires (tumoral et normal issus d'un même individu),\n",
    "    et qui fait appel aux fonctions quality_filter_normal et quality_filter_tumor afin de les filtrer,\n",
    "    selon les filtres retenus dans la liste reject.\n",
    "    \n",
    "    Return :\n",
    "    \n",
    "        filtered_df_tumor : dataframe tumoral filtré ;\n",
    "        \n",
    "        filtered_df_normal : dataframe normal fitré.\n",
    "            \n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_df_normal = quality_filter_normal(df_normal, reject, index=True)[0]\n",
    "    indexes2remove = quality_filter_normal(df_normal, reject, index=True)[1]\n",
    "    \n",
    "    filtered_df_tumor = quality_filter_tumor(df_tumor, indexes2remove, reject)\n",
    "    \n",
    "    print(\"Filtrage des variants de qualité :\", *reject, sep='\\n')\n",
    "    \n",
    "    return (filtered_df_tumor,\n",
    "           filtered_df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "portuguese-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succès : extension vcf détectée\n",
      "Succès : extension vcf détectée pour le fichier./samples/Sample1_normal_dna.vcf\n",
      "\n",
      "\n",
      "Succès : Format VCF détecté pour le fichier./samples/Sample1_normal_dna.vcf\n",
      "Succès : extension vcf détectée\n",
      "Succès : extension vcf détectée pour le fichier./samples/Sample1_tumor_dna.vcf\n",
      "\n",
      "\n",
      "Succès : Format VCF détecté pour le fichier./samples/Sample1_tumor_dna.vcf\n",
      "Succès : extension vcf détectée\n",
      "Succès : extension vcf détectée pour le fichier./samples/Sample1_somatic_dna.vcf\n",
      "\n",
      "\n",
      "Succès : Format VCF détecté pour le fichier./samples/Sample1_somatic_dna.vcf\n"
     ]
    }
   ],
   "source": [
    "sample1_normal = read_vcf(\"./samples/Sample1_normal_dna.vcf\")\n",
    "sample1_tumor = read_vcf(\"./samples/Sample1_tumor_dna.vcf\")\n",
    "sample1_somatic = read_vcf(\"./samples/Sample1_somatic_dna.vcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "possible-shell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161052 170921 251\n"
     ]
    }
   ],
   "source": [
    "print(len(sample1_normal), len(sample1_tumor), len(sample1_somatic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-teaching",
   "metadata": {},
   "source": [
    "## Creation de fichiers 'lite'  (chr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "strange-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_chr(df, chrom):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "    \n",
    "        df : dataframe.\n",
    "        \n",
    "        chrom : liste, le ou les chromosomes à conserver.\n",
    "        \n",
    "        Cette fonction permet de ne conserver qu'un ou plusieurs chromosomes parmi l'ensemble du dataframe,\n",
    "    afin de réduire le dataframe et ainsi reduire les temps de chargement pour la suite de ce pipeline\n",
    "    (ex : calcul du TMB qui peut être très long selon la taille du fichier etc ..)\n",
    "    \n",
    "    Return :\n",
    "    \n",
    "        new_df : dataframe n'ayant conservé que l'information sur les chromosomes renseignés par l'utilisateur.\n",
    "    \"\"\"\n",
    "    new_df = copy.deepcopy(df)\n",
    "    \n",
    "    if (len(chrom) == 1): #Garder un seul chromosome\n",
    "        new_df = df.loc[df[\"CHROM\"] == str(chrom[0])]\n",
    "        new_df.index = range(0, len(new_df), 1)  #reajustement des indexes\n",
    "        return(new_df)\n",
    "    \n",
    "    elif (len(chrom) >1): #Conserver plusieurs chromosomes\n",
    "        chrom = np.unique(sorted(chrom)) # numero chromosome dans l'ordre croissant\n",
    "        new_df = df.loc[df[\"CHROM\"] == str(chrom[0])]\n",
    "        for i in range(1, len(chrom), 1):\n",
    "            tmp_df = df.loc[df[\"CHROM\"] == str(chrom[i])]\n",
    "            new_df = pd.concat([new_df, tmp_df])\n",
    "            #print(len(tmp_df), len(new_df))\n",
    "            \n",
    "        new_df.index = range(0, len(new_df), 1)\n",
    "        #print(\"Seuls les chromosomes suivants ont bien été conservés : \", *chrom, sep = \"\\n\")\n",
    "        return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cubic-missile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage des variants de qualité :\n",
      "LowQual\n",
      "INDEL_SPECIFIC_FILTERS;LowQual\n"
     ]
    }
   ],
   "source": [
    "sample1_normal_test = select_chr(sample1_normal, ['1'])\n",
    "sample1_tumor_test = select_chr(sample1_tumor, ['1'])\n",
    "F_sample1_tumor_test,  F_sample1_normal_test= global_filter(sample1_tumor_test, sample1_normal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "charming-employment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'PASS': 14021,\n",
       "         'VQSRTrancheSNP99.90to100.00': 261,\n",
       "         'LowQual': 860,\n",
       "         'INDEL_SPECIFIC_FILTERS;LowQual': 125,\n",
       "         'INDEL_SPECIFIC_FILTERS': 51})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(F_sample1_normal_test['FILTER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-blues",
   "metadata": {},
   "source": [
    "## Test du QC des filtres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-memory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-disposal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "durable-server",
   "metadata": {},
   "source": [
    "## Quand on a tumor et normal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compound-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(df_tumor, df_normal):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "    \n",
    "        df_tumor : dataframe issu d'un vcf de tissu tumoral ;\n",
    "        \n",
    "        df_normal : dataframe issu d'un vcf de tissu sain ;\n",
    "    \n",
    "            On regarde si une mutation présente dans le fichier vcf tumoral est également présente \n",
    "        dans le fichier vcf sain (dit normal). Dans le cas échéant on ne compte pas cette mutation \n",
    "        comme étant une mutation propre à la tumeur, car elle est peut être localisée à d'autres \n",
    "        endroits dans l'organisme (simple SNP par exemple). \n",
    "        Dans le cas contraire on peut considèrer cette mutation comme étant somatique est propre à la tumeur.\n",
    "        \n",
    "    Return :\n",
    "    \n",
    "        indexes : liste d'ID de mutation présentes dans le dataframe tumoral et absente dans le normal.\n",
    "    \"\"\"\n",
    "    \n",
    "    CHROMS = np.unique(df_tumor['CHROM'].values)\n",
    "    indexes = []\n",
    "    \n",
    "    for _chr_ in CHROMS:\n",
    "        df_t = df_tumor.loc[df_tumor[\"CHROM\"] == _chr_]\n",
    "        df_n = df_normal.loc[df_normal[\"CHROM\"] == _chr_]\n",
    "        \n",
    "        df_t.index = range(0, len(df_t), 1)\n",
    "        df_n.index = range(0, len(df_n), 1)\n",
    "        \n",
    "        #df to np\n",
    "        POS_tumor = df_t['POS'].values\n",
    "        POS_normal = df_n['POS'].values\n",
    "        \n",
    "        for muta in df_t.index:\n",
    "            #print(_chr_)\n",
    "            NB_ALT_tumor = len(list(df_t['ALT'][muta]))\n",
    "            START = int(POS_tumor[muta])\n",
    "            END = START + len(list(df_t['ALT'][muta]))\n",
    "\n",
    "            #On identifie une mutation par ses positions de début et de fin (start et end)\n",
    "            if (START in list(POS_normal)): #même debut ?\n",
    "                # !!une meme position peut sur des chr differents!! \n",
    "                index = int(np.argwhere(POS_normal == START))\n",
    "                if (END == int(POS_normal[index]) + len(list(df_n['ALT'][index]) ) ): #même fin ?\n",
    "                    pass # non somatique\n",
    "                else:\n",
    "                    indexes.append(df_t['ID'][muta])\n",
    "            else:\n",
    "                indexes.append(df_t['ID'][muta])\n",
    "                \n",
    "    return (indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beneficial-scheduling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1696"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = compare(F_sample1_tumor_test, F_sample1_normal_test)\n",
    "len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sized-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_somatic(tumor_path, somatic_path, indexes):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "        tumor_path : chemin vers le fichier tumoral vcf ;\n",
    "        \n",
    "        somatic_path : chemin vers le futur fichier somatic vcf de sortie;\n",
    "        \n",
    "        indexes : indexes : liste d'ID de mutation présentes dans le dataframe tumoral et absente dans le normal. \n",
    "        \n",
    "        Cette fonction permet d'écrire dans un fichier toutes les mutations présentes dans le tissus tumoral,\n",
    "    et absentes dans le tissu normal. Cette comparaison est faite avec la fonction compare. \n",
    "    \n",
    "    Return :\n",
    "        \n",
    "        Rien (0)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    headers = []\n",
    "    lines = []\n",
    "\n",
    "    with open(tumor_path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            if line.startswith('#'):\n",
    "                headers.append(line)\n",
    "            elif not line.startswith('#'):\n",
    "                lines.append(line)\n",
    "\n",
    "    with open(somatic_path, \"w\") as f_out:\n",
    "        for i in range(len(headers)):\n",
    "                f_out.write(headers[i])\n",
    "        for j in range(len(lines)-1):\n",
    "            if (lines[j].split()[2] in indexes):\n",
    "                f_out.write(lines[j])\n",
    "                \n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "velvet-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_somatic(\"./samples/Sample1_tumor_dna.vcf\", \n",
    "               \"./Sample1_somatic_test.vcf\", indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-gates",
   "metadata": {},
   "source": [
    "## Annovar / bash to python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incomplete-duncan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"perl ./annovar/convert2annovar.pl -format vcf4 ./Sample1_somatic_test.vcf > ./Sample1_somatic_test.avinput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "continent-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"perl ./annovar/annotate_variation.pl -downdb -buildver hg19 -webfrom annovar refGene ./annovar/humandb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moral-bridal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"perl ./annovar/annotate_variation.pl -out ./Sample1_somatic_test -build hg19 ./Sample1_somatic_test.avinput ./annovar/humandb/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-desktop",
   "metadata": {},
   "source": [
    "## Calcul du TMB :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "civic-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_variants(infile, outfile, synonyme=False, coding=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "    \n",
    "        infile : fichier somatic obtenue après annovar ;\n",
    "        \n",
    "        outfile : fichier somatic filtré en ne gardant que certaines mutations (choix de l'utilisateur); \n",
    "        \n",
    "        synonyme : booléen, True : on garde les mutation synonymes, sinon False ;\n",
    "        \n",
    "        coding : booléen, True : on garde toutes les mutations qui touchent à la protéine finale\n",
    "                (ex : stop gain, stop loss, frameshift/nonframeshift, insertion/délection), sinon False.\n",
    "        \n",
    "        \n",
    "        Return :\n",
    "        \n",
    "            rien (0)\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(infile, \"r\") as infile, open(outfile, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            ligne=line.split()\n",
    "            if coding==True:\n",
    "                if synonyme==False and ligne[1]!=\"synonymous\" and ligne[1]!=\"unknown\" :\n",
    "                    outfile.write(line)\n",
    "                if synonyme==True and ligne[1]!=\"unknown\" :\n",
    "                    outfile.write(line)\n",
    "            if coding==False:\n",
    "                if synonyme==False and ligne[1]==\"nonsynonymous\" :\n",
    "                    outfile.write(line)\n",
    "                if synonyme==True and (ligne[1]==\"nonsynonymous\" or ligne[1]==\"synonymous\") :\n",
    "                    outfile.write(line)\n",
    "    return (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "computational-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMB_tumor_normal(somatic_infile, somatic_outfile, exome_length = 1, synonyme = False, coding = True):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "    \n",
    "        somatic_infile : fichier somatique.exonic_variant_function obtenue après annovar ;\n",
    "        \n",
    "        somatic_outfile : fichier filtrer après la fonction keep_variants ;\n",
    "        \n",
    "        exome_length : int, tailler de l'exome de référence pour calculer un taux.\n",
    "    \n",
    "    Return :\n",
    "    \n",
    "        TMB : float, Taux de mutation.\n",
    "    \"\"\"\n",
    "    keep_variants(somatic_infile, somatic_outfile, synonyme, coding)\n",
    "    \n",
    "    with open(somatic_outfile, 'r') as infile:\n",
    "        variants = [l for l in infile if not l.startswith('#')]\n",
    "    \n",
    "    TMB = len(variants) / exome_length\n",
    "    return (TMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "horizontal-montana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMB_tumor_normal( somatic_infile= \"./Sample1_somatic_test.exonic_variant_function\",\n",
    "             somatic_outfile= \"./Sample1_somatic_test.text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "virgin-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMB_somatic(somatic_infile, exome_length = 1):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "    \n",
    "        somatic_infile : fichier somatique.exonic_variant_function obtenue après annovar ;\n",
    "        \n",
    "        exome_length : int, tailler de l'exome de référence pour calculer un taux.\n",
    "    \n",
    "    Return :\n",
    "    \n",
    "        TMB : float, Taux de mutation.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(somatic_infile, 'r') as infile:\n",
    "        variants = [l for l in f if not l.startswith('#')]\n",
    "    \n",
    "    TMB = len(variants) / exome_length\n",
    "    return (TMB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-precipitation",
   "metadata": {},
   "source": [
    "## Quand on a que tumoral :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dietary-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"perl ./annovar/convert2annovar.pl -format vcf4 samples/Sample1_tumor_dna.vcf > samples/Sample1_tumor_dna.avinput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "focused-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"perl ./annovar/annotate_variation.pl -downdb -webfrom annovar -build hg19 exac03 annovar/humandb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "brown-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"perl ./annovar/annotate_variation.pl -filter -build hg19 -dbtype exac03 samples/Sample1_tumor_dna.avinput ./annovar/humandb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "communist-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMB_tumor (exac03, exome_length = 1):\n",
    "    \"\"\"\n",
    "    Argument : \n",
    "        exac03 : chemin vers fichier texte issus de annovar avec la probabilité pour chaque variant d'être associé \n",
    "        à la tumeur ;\n",
    "        \n",
    "        exome_length : int, tailler de l'exome de référence pour calculer un taux.\n",
    "        \n",
    "    Return : \n",
    "        \n",
    "        TMB : float, Taux de mutation.\n",
    "    \"\"\"\n",
    "    \n",
    "    TMB = 0\n",
    "    with open(str(exac03), \"r\") as exac03:\n",
    "        for line in exac03:\n",
    "            line_sp=line.split('\\t')\n",
    "            if float(line_sp[1]) == 0:\n",
    "                TMB += 1\n",
    "    return(TMB / exome_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "thirty-letters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMB_tumor(\"./samples/Sample1_tumor_dna.avinput.hg19_exac03_dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-empire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-consultancy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-score",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Y9bzornPhxQC",
    "FoaE_Bl-QM4K",
    "J5oUc3KYQURS",
    "lQx-hYoNaMkj"
   ],
   "name": "Pipeline-TMB-notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
